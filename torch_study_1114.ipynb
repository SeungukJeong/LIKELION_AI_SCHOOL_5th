{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "iris= load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "..      ...  \n",
      "145     2.0  \n",
      "146     2.0  \n",
      "147     2.0  \n",
      "148     2.0  \n",
      "149     2.0  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n",
    "\n",
    "y = data['target']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.1, 3.5, 1.4, 0.2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.tolist()\n",
    "x.iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.x_data = df.iloc[:, :-1] # x data dataframe으로 \n",
    "        self.y_data = df['target'] # y data target\n",
    "   \n",
    "    #총 데이터 개수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    #인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 Pytorch Tensor 형태로 전환\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data.iloc[idx].tolist()\n",
    "        x = torch.tensor(x)\n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data)\n",
    "dataloadeer = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.8000, 2.8000, 5.1000, 2.4000]])\n",
      "tensor([2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data를 분리해서 클래스 ( )안에 넣는다면?\n",
    "\n",
    "\n",
    "# x_train, x_valid, y_train, y_valid = train\n",
    "split_ratio = 0.7\n",
    "split_index = int(split_ratio * len(data))\n",
    "\n",
    "# train shuffle test not shuffle\n",
    "\n",
    "train_dataset = CustomDataset(data[ : split_index ])\n",
    "test_dataset = CustomDataset(data[split_index : ])\n",
    "\n",
    "dataLoader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "dataiter = iter(dataLoader)\n",
    "\n",
    "feature, target = dataiter.next() # 값 확인하는 용으로 data 잘 들어가는 가 batch 마다\n",
    "\n",
    "print(feature)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "split_index = int(split_ratio * len(data))\n",
    "\n",
    "train_dataset = CustomDataset(data[: split_index ])\n",
    "test_dataset = CustomDataset(data[split_index : ]) \n",
    "\n",
    "train_dataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.4000, 2.9000, 4.3000, 1.3000]])\n",
      "tensor([1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataLoader)\n",
    "\n",
    "feature, target = dataiter.next() # 값 확인하는 용으로 data 잘 들어가는 가 batch 마다\n",
    "\n",
    "print(feature)\n",
    "print(target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7845274933dd615419e1afd758a737ba48a9635507273f293d1fa6c35d52d41e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('torch_study': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
